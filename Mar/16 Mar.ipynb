{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40994649-f531-495c-bc9e-3142c90d9251",
   "metadata": {},
   "source": [
    "### Q1: Define overfitting and underfitting in machine learning. What are the consequences of each, and how can they be mitigated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1500788-3e4a-4b4f-a0ee-33696d90ce5a",
   "metadata": {},
   "source": [
    "* Overfitting occurs when a model is trained too well on the training data, and it starts to learn the noise in the data instead of the underlying pattern.\n",
    "* As a result, the model performs well on the training data but poorly on new data. \n",
    "* Underfitting occurs when a model is too simple to capture the underlying pattern in the data. The model performs poorly on both the training data and new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e5c7b0-f214-4c30-93cc-ccc6c1fc9244",
   "metadata": {},
   "source": [
    "\n",
    "### Q2: How can we reduce overfitting? Explain in brief.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaa14a9-066a-4ce8-b72e-5204b2db322c",
   "metadata": {},
   "source": [
    "* To reduce overfitting, we can use regularization techniques such as L1 and L2 regularization, dropout, and early stopping.\n",
    "* Regularization techniques add a penalty term to the loss function, which discourages the model from overfitting.\n",
    "* Dropout randomly drops out some neurons during training, which helps the model generalize better.\n",
    "* Early stopping stops the training process when the model starts to overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead48b5e-66b4-4f6e-8b51-42565ebee31c",
   "metadata": {},
   "source": [
    "### Q3: Explain underfitting. List scenarios where underfitting can occur in ML.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc6621-d80f-4f46-a200-ee121c21d08c",
   "metadata": {},
   "source": [
    "* Underfitting occurs when a model is too simple to capture the underlying pattern in the data.\n",
    "* It can occur when the model is too shallow, has too few parameters, or is not trained for long enough. Underfitting can also occur when the data is too noisy or when the model is too constrained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43c64a5-1687-4fc7-b975-764b2e589ead",
   "metadata": {},
   "source": [
    "### Q4: Explain the bias-variance tradeoff in machine learning. What is the relationship between bias and variance, and how do they affect model performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d3a246-aa86-4b10-aae4-d35187104ed0",
   "metadata": {},
   "source": [
    "* The bias-variance tradeoff is a fundamental concept in machine learning. \n",
    "* ***Bias refers*** to the error that is introduced by approximating a real-world problem with a simplified model. \n",
    "* ***Variance*** refers to the error that is introduced by the model’s sensitivity to small fluctuations in the training data.\n",
    "* High bias models are too simple and underfit the data, while high variance models are too complex and overfit the data.\n",
    "The goal is to find a balance between bias and variance that minimizes the model’s error on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b694d9-5bbb-4939-8316-cb9e9c19ba56",
   "metadata": {},
   "source": [
    "### Q5: Discuss some common methods for detecting overfitting and underfitting in machine learning models. How can you determine whether your model is overfitting or underfitting?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a5618e-c009-4f14-a2da-897280e4eebe",
   "metadata": {},
   "source": [
    "* Common methods for detecting overfitting and underfitting include cross-validation, learning curves, and performance on the validation set.\n",
    "\n",
    "***Cross-validation***  involves splitting the data into training and validation sets and evaluating the model’s performance on the validation set. Learning curves plot the model’s performance on the training and validation sets as a function of the training set size. Performance on the validation set is a good indicator of overfitting and underfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d9b013-6070-47f4-a8a6-dd59dc2ec9c8",
   "metadata": {},
   "source": [
    "### Q6: Compare and contrast bias and variance in machine learning. What are some examples of high bias and high variance models, and how do they differ in terms of their performance?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce747387-91b1-4c4f-b870-cd33419be463",
   "metadata": {},
   "source": [
    "* Bias and variance are two sources of error in machine learning models. \n",
    "* High bias models are too simple and underfit the data, \n",
    "* High variance models are too complex and overfit the data.\n",
    "\n",
    "* An example of a high bias model is linear regression, while an example of a high variance model is a decision tree with no pruning. High bias models have low variance, while high variance models have low bias. The goal is to find a balance between bias and variance that minimizes the model’s error on new data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa5e182-1dde-44e3-ab7d-137cb02240c7",
   "metadata": {},
   "source": [
    "### Q7: What is regularization in machine learning, and how can it be used to prevent overfitting? Describe some common regularization techniques and how they work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0658b2fe-3e79-4f03-bc96-a8db47338ef7",
   "metadata": {},
   "source": [
    "* Regularization is a technique used to prevent overfitting by adding a penalty term to the loss function. \n",
    "* Common regularization techniques include L1 and L2 regularization, dropout, and early stopping. \n",
    "* L1 regularization adds a penalty term proportional to the absolute value of the weights, while L2 regularization adds a penalty term proportional to the square of the weights.\n",
    "* Dropout randomly drops out some neurons during training, which helps the model generalize better. Early stopping stops the training process when the model starts to overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bdaf78-0294-476f-aec1-e7711129946b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
